[*] Warning: models are not being checkpoint
[*] Setting Randomness...
[2025-09-15 00:22:02,133][jax._src.xla_bridge][INFO] - Unable to initialize backend 'cuda':
[2025-09-15 00:22:02,134][jax._src.xla_bridge][INFO] - Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'
[2025-09-15 00:22:02,135][jax._src.xla_bridge][INFO] - Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
[2025-09-15 00:22:02,137][jax._src.xla_bridge][WARNING] - An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.
[*] Generating MNIST Classification Dataset...
[*] Starting `s4` Training on `mnist-classification` =>> Initializing...
/home/jaxon/research/fault-injection/ssm-fault-inj/s4/train.py:131: DeprecationWarning: jax.tree_leaves is deprecated: use jax.tree.leaves (jax v0.4.25 or newer) or jax.tree_util.tree_leaves (any JAX version).
  extra_keys = set(lr_layer.keys()) - set(jax.tree_leaves(name_map(params)))
/home/jaxon/research/fault-injection/ssm-fault-inj/s4/train.py:143: DeprecationWarning: jax.tree_leaves is deprecated: use jax.tree.leaves (jax v0.4.25 or newer) or jax.tree_util.tree_leaves (any JAX version).
  print(f"[*] Trainable Parameters: {sum(jax.tree_leaves(param_sizes))}")
[*] Trainable Parameters: 397834
[*] Total training steps: 4690
[*] Starting Training Epoch 1...
100%|██████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [36:01<00:00,  4.61s/it]
[*] Running Epoch 1 Validation...
  0%|                                                                                                         | 0/79 [00:00<?, ?it/s]
injecting faults
Error executing job with overrides: []
jax.errors.SimplifiedTraceback: For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/jaxon/research/fault-injection/ssm-fault-inj/s4/train.py", line 465, in main
    example_train(**cfg)
  File "/home/jaxon/research/fault-injection/ssm-fault-inj/s4/train.py", line 366, in example_train
    test_loss, test_acc = validate(
  File "/home/jaxon/research/fault-injection/ssm-fault-inj/s4/train.py", line 190, in validate
    loss, acc = eval_step(
  File "/home/jaxon/research/fault-injection/ssm-fault-inj/s4/train.py", line 252, in eval_step
    logits = model.apply({"params": params}, batch_inputs)
  File "/home/jaxon/research/fault-injection/ssm-fault-inj/s4/s4.py", line 619, in __call__
    x = layer(x)
  File "/home/jaxon/research/fault-injection/ssm-fault-inj/s4/s4.py", line 560, in __call__
    x = random_bitflip(x, error_rate=1e-3)
  File "/home/jaxon/research/fault-injection/ssm-fault-inj/s4/s4.py", line 112, in random_bitflip
    float_bits = np.array(flat_output, dtype=np.float32).view(np.uint32)
jax.errors.TracerArrayConversionError: The numpy.ndarray conversion method __array__() was called on traced array with shape float32[100352].
This BatchTracer with object id 131252054855568 was created on line:
  /home/jaxon/research/fault-injection/ssm-fault-inj/s4/s4.py:111 (random_bitflip)
See https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerArrayConversionError

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
